{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prep abstracts for LDA\n",
    "\n",
    "The overall goal for this script is to filter through each year's worth of abstracts from 1985-2016 that are **(1) neuroscience-related** and **(2) R01s**.\n",
    "\n",
    "For each abstract that met those conditions, I decomposed that abstract into a list of words that were lowercase, with punctuation removed, stemmed, and also removed the stopwords. I then saved each wordlist, with the corresponding year, into a csv file, *all_years.csv*, containing abstract wordlists for 1985-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import some packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read abstracts and project csvs into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize a dataframe\n",
    "initialize_df = pd.DataFrame(columns=['wordlist', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write dataframe to csv file\n",
    "try: \n",
    "    initialize_df.to_csv('all_years.csv')\n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_abstracts_projects(year):\n",
    "    \"\"\"\n",
    "    input: int -- year to analyze; [1985:2016] inclusive.\n",
    "    returns: 2 dataframes -- project & abstract\n",
    "    \"\"\"\n",
    "    abs_dir = './abstracts/'\n",
    "    proj_dir = './projects/'\n",
    "    \n",
    "    project = pd.read_csv(proj_dir + 'RePORTER_PRJ_C_FY' + year + '.csv', encoding = \"ISO-8859-1\")\n",
    "    abstract = pd.read_csv(abs_dir + 'RePORTER_PRJABS_C_FY' + year + '.csv',encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    return project, abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clean and filter for neuro abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Clean abstracts (stemming, lowercase, no punctuation, remove stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get customized stopwords:\n",
    "def customized_stopwords(to_append=[]):\n",
    "    \"\"\"\n",
    "    to_append: list; what words do you want to exclude from your analysis, in addition to the standard \n",
    "    stopwords like 'the', 'and, 'of', and so on? See above to_append variable for examples.\n",
    "    returns: list; stopwords including to_append list\n",
    "    \"\"\"\n",
    "    stop = stopwords.words('english')\n",
    "    stop = stop + to_append\n",
    "    return stop\n",
    "\n",
    "# get list of words that are lowercase, with punctuation removed and words stemmed.\n",
    "def get_wordlist(abstract, stop = customized_stopwords()):\n",
    "    \"\"\"\n",
    "    returns a list of lowercase words from abstract with punctuation and stopwords removed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # make words lowercase\n",
    "        words = abstract.lower()\n",
    "        \n",
    "        # take out all punctuation and split strings into a list of words\n",
    "        words = (''.join(c for c in words if c not in punctuation)).split(' ')\n",
    "        \n",
    "        # remove stopwords\n",
    "        words = [\" \".join([w for w in word.split() if not w in stop]) for word in words]\n",
    "        \n",
    "        # stem words using Porter's Stemmer\n",
    "        stemmed = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                word = PorterStemmer().stem(word)\n",
    "            except IndexError:\n",
    "                word = word\n",
    "            if word != '' and word.isalpha():\n",
    "                stemmed.append(word)\n",
    "        words = stemmed\n",
    "\n",
    "    except AttributeError:\n",
    "        words = []\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Filter for neuro-related abstracts.\n",
    "I defined a project to be neuroscience-related if the abstract mentioned \"brain\" or \"neur*\" at least once every 100 non-stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neuro_count(row):\n",
    "    try:\n",
    "        return (row.ABSTRACT_TEXT.count(' brain') + row.ABSTRACT_TEXT.count('neur'))\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "    \n",
    "def wordlist_count(row):\n",
    "    return len(row.wordlist)\n",
    "    \n",
    "def neuro_only(df, word_density=0.01):\n",
    "    \"\"\"\n",
    "    input: dataframe\n",
    "    word_density: how many neuro related words for every 100 words that are not stopwords in an abstract? Stopwords: the, and, or, not, etc.\n",
    "    returns: dataframe containing neuro-related projects as defined above, with a column containing cleaned abstract keywords for analysis.\n",
    "    \"\"\"\n",
    "    df['abs_neuro_count'] = df.apply(neuro_count, axis=1)\n",
    "    df['wordlist'] = df.ABSTRACT_TEXT.apply(get_wordlist)\n",
    "    df['wordlist_ct'] = df.apply(wordlist_count, axis=1)\n",
    "    df['rel_neuro_count'] = df.abs_neuro_count / df.wordlist_ct\n",
    "    \n",
    "    # drop duplicates - I found that in some years, there are duplicate abstracts which really screwed up my hierarchical clustering\n",
    "    df = df.drop_duplicates('ABSTRACT_TEXT')\n",
    "    return df[df.rel_neuro_count >= word_density]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996 done\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "years = range(1985,2017)\n",
    "grant_type = 'R01'\n",
    "\n",
    "# get abstracts and projects for a single year\n",
    "for year in years:\n",
    "    project, abstract = get_abstracts_projects(str(year))\n",
    "\n",
    "    # join abstracts to projects dataframe\n",
    "    df = project.merge(abstract, on='APPLICATION_ID', how='left')\n",
    "    \n",
    "    # Implement clean abstracts and filter for neuro projects.\n",
    "    df_neuro = neuro_only(df)\n",
    "\n",
    "    # look only at R01s\n",
    "    df_neuro_granttype = df_neuro[df_neuro.ACTIVITY == grant_type]\n",
    "\n",
    "    # save wordlist and year to csv file\n",
    "    df_to_save = pd.DataFrame(df_neuro_granttype['wordlist'])\n",
    "    df_to_save['year'] = year\n",
    "    df_to_save.to_csv('all_years.csv', mode='a', header=False)\n",
    "    \n",
    "    print (year, 'done')\n",
    "print ('all done')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
